# Model-Testing
**The python notebook can be used to test the performance of LLM models.** 
The script is designed to evaluate the performance of various language models in text summarization tasks. It begins by installing necessary packages and importing required libraries, then sets up a text prompt template for summarization instructions. Utilizing the Hugging Face Hub, the script initializes and compares several language models, including Mistral models (Mistral-8x7B-Instruct-v0.1, Mistral-7B-Instruct-v0.2), Falcon model (falcon-7b-instruct), and BART model (bart-large-cnn), each configured with specific parameters. Additionally, it incorporates the Gemini model from Google Generative AI. The script generates summaries for a given input text using each model and records the execution time for evaluation purposes. The main purpose of the script is to provides a comprehensive framework for assessing the summarization capabilities of various large language models.
